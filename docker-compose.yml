version: '1.1'

services:
  tgen_service: # 내가 원하는 서비스 이름
    image: tgen:1.1
    container_name: tgen
    # runtime: nvidia
    devices:
      # - /dev/nvidia0
      - nvidia.com/gpu=all
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           device_ids: ["3"]
    #           capabilities: [gpu]
    tty: true
    ipc : host
    volumes:
      - .:/app/OpenVoice:z
      - ./h_models:/root/.cache/huggingface/hub/:z
      - ./dataset:/root/nltk_data/corpora/:z
    ports:
      - "8081:8081"
    working_dir: /app/OpenVoice
    environment:
      - LD_LIBRARY_PATH=/usr/local/lib/python3.9/dist-packages/nvidia/cudnn/lib
    entrypoint:
      ["python3.9", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8081", "--reload"]
    # ["gunicorn", "-w", "3", "-k", "uvicorn.workers.UvicornWorker", "main:app", "--bind", "0.0.0.0:8083", "--reload"]